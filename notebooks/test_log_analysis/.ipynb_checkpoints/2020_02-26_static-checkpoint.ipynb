{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Log Analysis and Visulization 2020-02-26"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## a) parse log file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import shutil\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the log file\n",
    "def is_json(myjson):\n",
    "    try:\n",
    "        json_object = json.loads(myjson)\n",
    "    except ValueError as e:\n",
    "        return False\n",
    "    return True\n",
    " \n",
    "def read_data(files, path):\n",
    "    data = []\n",
    "    for file in files:\n",
    "        with open(path + file, errors='ignore') as f:\n",
    "            for line in f.readlines():\n",
    "                try: \n",
    "                    if not is_json(line):\n",
    "                        continue\n",
    "                    data.append(json.loads(line))\n",
    "                except:\n",
    "                    print('bad json: ', line)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## b) data processing and analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the data into pandas dataframe\n",
    "def data_processing(data):\n",
    "    df = pd.DataFrame(data) \n",
    "\n",
    "    # convert all the keys in the staking into columns, fill nan values\n",
    "    df = pd.concat([df.drop(['staking'], axis=1), df['staking'].apply(pd.Series)], axis=1)\n",
    "    df.fillna(0, inplace = True)\n",
    "\n",
    "    # drop duplicates\n",
    "    df.drop_duplicates(inplace = True)\n",
    "\n",
    "    # sort by timestamp \n",
    "    df.sort_values(by=['timestamp'], inplace = True)\n",
    "\n",
    "    # convert timestamp to datetime64[ns] \n",
    "    df[\"timestamp\"] = df[\"timestamp\"].apply(lambda t: t.replace(\" +0000 UTC\",\"\"))\n",
    "    df[\"timestamp\"] = pd.to_datetime(df['timestamp'])\n",
    "    df['utc_time'] = df['timestamp'].dt.time\n",
    "    \n",
    "    df[\"log_size\"] = df.apply(lambda c: np.log(c[\"size\"]) if c[\"size\"] != 0 else 0, axis = 1)\n",
    "    df[\"log_gas\"] = df.apply(lambda c: np.log(c[\"gas\"]) if c[\"gas\"] != 0 else 0, axis = 1)\n",
    "    \n",
    "    # do calculation for each shard\n",
    "    shard = []\n",
    "    for name, s in df.groupby(\"shard\"):\n",
    "        shard.append(s.reset_index(drop = True))\n",
    "    \n",
    "    # calculate the average time per block, transaction_per_second\n",
    "    for s in shard:\n",
    "        # time per block\n",
    "        s[\"time_diff\"] = (s['timestamp']-s['timestamp'].shift()).fillna(pd.Timedelta(seconds=0))\n",
    "        s[\"block_diff\"] = (s['block']-s['block'].shift()).fillna(0).astype(int)\n",
    "        s[\"time_per_block\"] = s.apply(lambda c: c[\"time_diff\"].seconds /c[\"block_diff\"] \\\n",
    "                                      if c[\"block_diff\"] != 0 else np.nan, axis = 1)\n",
    "\n",
    "        # plain transaction_per_second\n",
    "        s[\"transaction_per_second\"] = s.apply(lambda c: c[\"transactions\"]/c[\"time_diff\"].seconds  \\\n",
    "                                              if c[\"time_diff\"].seconds != 0 else np.nan, axis = 1)\n",
    "        # staking transaction_per_second\n",
    "        s[\"staking_transaction_per_second\"] = s.apply(lambda c: c[\"total\"]/c[\"time_diff\"].seconds \\\n",
    "                                              if c[\"time_diff\"].seconds != 0 else np.nan, axis = 1)\n",
    "        # total transacton per second\n",
    "        s[\"total_transaction_per_second\"] = s[\"transaction_per_second\"] + s[\"staking_transaction_per_second\"]\n",
    "\n",
    "        # info for staking\n",
    "        s.rename(columns={\"total\": \"total_staking\"}, inplace = True)\n",
    "        if \"CreateValidator\" in s.columns:\n",
    "            # create validator per second\n",
    "            s[\"create_validator_per_second\"] = s.apply(lambda c: c[\"CreateValidator\"]/c[\"time_diff\"].seconds \\\n",
    "                                                       if c[\"time_diff\"].seconds != 0 else np.nan, axis = 1)\n",
    "        if \"EditValidator\" in s.columns:\n",
    "            # edit validator per second\n",
    "            s[\"edit_validator_per_second\"] = s.apply(lambda c: c[\"EditValidator\"]/c[\"time_diff\"].seconds \\\n",
    "                                                       if c[\"time_diff\"].seconds != 0 else np.nan, axis = 1)\n",
    "        if \"Delegate\" in s.columns:\n",
    "            # delegate per second\n",
    "            s[\"delegate_per_second\"] = s.apply(lambda c: c[\"Delegate\"]/c[\"time_diff\"].seconds \\\n",
    "                                                       if c[\"time_diff\"].seconds != 0 else np.nan, axis = 1)\n",
    "        if \"Undelegate\" in s.columns:\n",
    "            # undelegate per second\n",
    "            s[\"undelegate_per_second\"] = s.apply(lambda c: c[\"Undelegate\"]/c[\"time_diff\"].seconds \\\n",
    "                                                       if c[\"time_diff\"].seconds != 0 else np.nan, axis = 1)\n",
    "        if \"CollectRewards\" in s.columns:\n",
    "            # CollectRewards per second\n",
    "            s[\"collect_rewards_per_second\"] = s.apply(lambda c: c[\"CollectRewards\"]/c[\"time_diff\"].seconds \\\n",
    "                                                       if c[\"time_diff\"].seconds != 0 else np.nan, axis = 1)\n",
    "            \n",
    "        s.drop(['time_diff', 'block_diff'], axis=1, inplace = True)\n",
    "        \n",
    "    return shard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## c) draw the graph "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# draw the graphs with x-axis time\n",
    "def draw_graph_time(shard, fig_path):\n",
    "    df = pd.concat(shard)\n",
    "    \n",
    "    sns.set(style=\"whitegrid\", font_scale = 1.8)\n",
    "    colors = [\"#00AEE9\",\"#758796\",\"#1B295E\"]\n",
    "    new_palette = sns.set_palette(colors)\n",
    "    \n",
    "    fig = plt.figure(figsize=(20, 10))\n",
    "    ax = sns.lineplot(x=\"utc_time\", y=\"transaction_per_second\", hue=\"shard\", data=df)\n",
    "    ax.set_title('Transaction Per Second vs Time ')\n",
    "    fig.savefig(fig_path + \"transaction_per_second_vs_time.png\")\n",
    "    plt.show()\n",
    "    \n",
    "    fig = plt.figure(figsize=(20, 10))\n",
    "    ax = sns.lineplot(x=\"utc_time\", y=\"time_per_block\", hue=\"shard\", data=df)\n",
    "    ax.set_title('Time Per Block vs Time ')\n",
    "    fig.savefig(fig_path + \"time_per_block_vs_time.png\")\n",
    "    plt.show()\n",
    "    \n",
    "    fig = plt.figure(figsize=(20, 10))\n",
    "    ax = sns.lineplot(x=\"utc_time\", y=\"size\", hue=\"shard\", data=df)\n",
    "    ax.set_title(\"Size vs Time \")\n",
    "    fig.savefig(fig_path + \"size_vs_time.png\")\n",
    "    plt.show()\n",
    "    \n",
    "    fig = plt.figure(figsize=(20, 10))\n",
    "    ax = sns.lineplot(x=\"utc_time\", y=\"gas\", hue=\"shard\", data=df)\n",
    "    ax.set_title(\"Gas vs Time \")\n",
    "    fig.savefig(fig_path + \"gas_vs_time.png\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# draw the graphs with x-axis block height\n",
    "def draw_graph_block(shard, fig_path):\n",
    "    df = pd.concat(shard)\n",
    "    \n",
    "    sns.set(style=\"whitegrid\", font_scale = 1.8)\n",
    "    colors = [\"#00AEE9\",\"#758796\", \"#1B295E\"]\n",
    "    sns.set_palette(sns.color_palette(colors))\n",
    "    \n",
    "    fig = plt.figure(figsize=(20, 10))\n",
    "    ax = sns.lineplot(x=\"block\", y=\"transaction_per_second\", hue=\"shard\", data=df)\n",
    "    ax.set_title('Transaction Per Second vs Block Height ')\n",
    "    fig.savefig(fig_path + \"transaction_per_second_vs_block_height.png\")\n",
    "    plt.show()\n",
    "    \n",
    "    fig = plt.figure(figsize=(20, 10))\n",
    "    ax = sns.lineplot(x=\"block\", y=\"time_per_block\", hue=\"shard\", data=df)\n",
    "    ax.set_title('Time Per Block vs Block Height ')\n",
    "    fig.savefig(fig_path + \"time_per_block_vs_block_height.png\")\n",
    "    plt.show()\n",
    "    \n",
    "    fig = plt.figure(figsize=(20, 10))\n",
    "    ax = sns.lineplot(x=\"block\", y=\"size\", hue=\"shard\", data=df)\n",
    "    ax.set_title(\"Size vs Block Height \")\n",
    "    fig.savefig(fig_path + \"size_vs_block_height.png\")\n",
    "    plt.show()\n",
    "    \n",
    "    fig = plt.figure(figsize=(20, 10))\n",
    "    ax = sns.lineplot(x=\"block\", y=\"gas\", hue=\"shard\", data=df)\n",
    "    ax.set_title(\"Gas vs Block Height \")\n",
    "    ax = fig.savefig(fig_path + \"gas_vs_block_height.png\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Result\n",
    "- transaction per second vs time \n",
    "- time per block vs time\n",
    "- size vs time\n",
    "- gas vs time\n",
    "- transaction per second vs block height\n",
    "- time per block vs block height\n",
    "- size vs block height\n",
    "- gas vs block height"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../../logs/test_logs/sress_test_02_26/'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-2e9b3e15e64f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mlog_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"../../logs/test_logs/sress_test_02_26/\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mfig_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"../../graphs/test_logs/sress_test_02_26/\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mfiles\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiles\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mshard\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_processing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../../logs/test_logs/sress_test_02_26/'"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    log_path = \"../../logs/test_logs/sress_test_02_26/\"\n",
    "    fig_path = \"../../graphs/test_logs/sress_test_02_26/\"\n",
    "    files = os.listdir(log_path)\n",
    "    data = read_data(files, log_path)\n",
    "    shard = data_processing(data)\n",
    "    new = pd.concat(shard)\n",
    "    \n",
    "    for name, group in new.groupby(\"shard\"):\n",
    "        print(\"statistics summary for shard \" + str(name))\n",
    "        print(\"==================================\")\n",
    "        summary = group[[\"size\",\"gas\",\"transaction_per_second\",\"time_per_block\"]].describe()\n",
    "        print(\"Total data points: \" + str(summary.iloc[0][0].astype(int)))\n",
    "        print(summary.iloc[1:])\n",
    "        print(\"\")\n",
    "        \n",
    "    if os.path.exists(fig_path):\n",
    "        shutil.rmtree(fig_path)\n",
    "        os.mkdir(fig_path)\n",
    "        print(\"Features vs Time\")\n",
    "        print(\"==================================\")\n",
    "        draw_graph_time(shard, fig_path)\n",
    "        print(\"Features vs Block Height\")\n",
    "        print(\"==================================\")\n",
    "        draw_graph_block(shard, fig_path)\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
